{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from project import run\n",
    "\n",
    "# setting display options\n",
    "%matplotlib inline\n",
    "pd.set_option('display.width', 4000)\n",
    "pd.set_option('max_colwidth', 4000)\n",
    "pd.set_option('max_rows', 100)\n",
    "pd.set_option('max_columns', 200)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values of \"Area\" column were imputed.\n",
      "NaN values of \"Education\" column were imputed.\n",
      "NaN values of \"Children\" column were imputed.\n",
      "    First_Policy  Birthday Education  Salary Area Children     CMV  Claims  Motor  Household  Health  Life  Work_Compensation\n",
      "ID                                                                                                                           \n",
      "1           1985      1982      2.00    2177 1.00     1.00  380.97    0.39   0.57      -0.55   -0.29  0.24              -0.54\n",
      "2           1981      1995      2.00     677 4.00     1.00 -131.13    1.12  -1.59       0.96   -0.69  0.00               1.75\n"
     ]
    }
   ],
   "source": [
    "my_path = r'./data/insurance.db'\n",
    "\n",
    "df = run(my_path, nb_exploration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First_Policy</th>\n",
       "      <th>Birthday</th>\n",
       "      <th>Education</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Area</th>\n",
       "      <th>Children</th>\n",
       "      <th>CMV</th>\n",
       "      <th>Claims</th>\n",
       "      <th>Motor</th>\n",
       "      <th>Household</th>\n",
       "      <th>Health</th>\n",
       "      <th>Life</th>\n",
       "      <th>Work_Compensation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1985</td>\n",
       "      <td>1982</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2177</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>380.97</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1981</td>\n",
       "      <td>1995</td>\n",
       "      <td>2.00</td>\n",
       "      <td>677</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-131.13</td>\n",
       "      <td>1.12</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1991</td>\n",
       "      <td>1970</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2277</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>504.67</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1990</td>\n",
       "      <td>1981</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1099</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-16.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>1.92</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1986</td>\n",
       "      <td>1973</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1763</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>35.23</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    First_Policy  Birthday Education  Salary Area Children     CMV  Claims  Motor  Household  Health  Life  Work_Compensation\n",
       "ID                                                                                                                           \n",
       "1           1985      1982      2.00    2177 1.00     1.00  380.97    0.39   0.57      -0.55   -0.29  0.24              -0.54\n",
       "2           1981      1995      2.00     677 4.00     1.00 -131.13    1.12  -1.59       0.96   -0.69  0.00               1.75\n",
       "3           1991      1970      1.00    2277 3.00     0.00  504.67    0.28  -0.66       0.10   -0.58  1.27               1.57\n",
       "4           1990      1981      3.00    1099 4.00     1.00  -16.99    0.99  -0.83      -0.71    1.92 -0.07              -0.24\n",
       "5           1986      1973      3.00    1763 4.00     1.00   35.23    0.90   0.30      -0.69    0.20 -0.50               0.09"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "First_Policy            int32\n",
       "Birthday                int32\n",
       "Education            category\n",
       "Salary                  int32\n",
       "Area                 category\n",
       "Children             category\n",
       "CMV                   float64\n",
       "Claims                float64\n",
       "Motor                 float64\n",
       "Household             float64\n",
       "Health                float64\n",
       "Life                  float64\n",
       "Work_Compensation     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['First_Policy', 'Birthday', 'Education', 'Salary', 'Area', 'Children', 'CMV', 'Claims', 'Motor', 'Household', 'Health', 'Life', 'Work_Compensation'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "premiums_cols = [\"Motor\", \"Household\", \"Health\", \"Life\", \"Work_Compensation\"]\n",
    "categorical_cols = [\"Area\", \"Education\", \"Children\"]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the variables into Value / Engage and Consumption / Affinity\n",
    "\n",
    "ValueEngage = df[['Age',\n",
    "               'Education',\n",
    "               'Salary',\n",
    "               'Area',\n",
    "               'Children',\n",
    "               'CMV',\n",
    "               'Claims',\n",
    "               'Customer_Years']]\n",
    "\n",
    "ConsAff = df.loc[:,[ 'Motor',\n",
    "               'Household',\n",
    "               'Health',\n",
    "               'Life',\n",
    "               'Work_Compensation']].reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_for_clustering = []\n",
    "# cols_for_clustering.extend(premiums_cols)\n",
    "# cols_for_clustering.extend(categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr = df.corr(method='pearson')\n",
    "\n",
    "# Obtain Correlation and plot it\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "h_map = sns.heatmap(corr, \n",
    "            xticklabels=corr.columns,\n",
    "            yticklabels=corr.columns,\n",
    "            cmap='PRGn', annot=True, linewidths=.5)\n",
    "\n",
    "#this is fix for matplotlib3.1.1 to ensure the top and bottom rows are not cut off.\n",
    "# According to: https://github.com/mwaskom/seaborn/issues/1773#issuecomment-546466986\n",
    "bottom, top = h_map.get_ylim()\n",
    "h_map.set_ylim(bottom + 0.5, top - 0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might be handy: https://github.com/joaolcorreia/RFM-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "df[:] = StandardScaler().fit_transform(df[:])\n",
    "\n",
    "x = df[df.columns.difference(categorical_cols + premiums_cols)].values # excluding categorical columns\n",
    "x = x[:200] # slice array for faster cluster testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Fitting the PCA algorithm with our Data\n",
    "pca = PCA().fit(df)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "# Plotting the Cumulative Summation of the Explained Variance\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.title('Explained Variance')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9 components explain 94.20951% of the variance. So, we'll use 9 components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=9)\n",
    "principalComponents = pca.fit_transform(df)\n",
    "\n",
    "principalDf = pd.DataFrame(data = principalComponents, columns = ['pc_1', 'pc_2', 'pc_3', 'pc_4', 'pc_5', 'pc_6',\n",
    "                                                                  'pc_7', 'pc_8', 'pc_9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Components: ', pca.components_)\n",
    "print('Explained Variance: ', pca.explained_variance_)\n",
    "print('Explained Variance Ratio: ', pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "principalDf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # do we need to show the PCA some how? so I try to do with T-SNE\n",
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# tsne = TSNE(n_components=2, verbose=0, perplexity=40, n_iter=300)\n",
    "# tsne_pca_results = tsne.fit_transform(principalDf)\n",
    "\n",
    "# tsne_data = np.vstack((tsne_pca_results.T, principalDf.index)).T\n",
    "\n",
    "# tsne_df = pd.DataFrame(data=tsne_data, columns = ('Dim_1', 'Dim_2', 'label'))\n",
    "\n",
    "# sns.FacetGrid(tsne_df, hue='label', height=6).map(plt.scatter, 'Dim_1', 'Dim_2', alpha=.7)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_subset = df.copy()\n",
    "# df_subset = df_subset.T\n",
    "# df_subset['tsne-pca-one'] = tsne_pca_results[:,0]\n",
    "# df_subset['tsne-pca-two'] = tsne_pca_results[:,1]\n",
    "\n",
    "# ax = plt.subplot(1,3,3)\n",
    "# sb.scatterplot(\n",
    "#     x='tsne-pca-one', y='tsne-pca-one',\n",
    "#     hue=df.columns,\n",
    "#     palette=sb.color_palette('hls', 10),\n",
    "#     data = df_subset,\n",
    "#     legend = 'full',\n",
    "#     alpha = 0.3\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(principalDf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only if PCA is 2 components:\n",
    "# plt.scatter(principalDf.iloc[:, 0], principalDf.iloc[:, 1])\n",
    "# # plt.scatter(principalComponents[:,0], principalComponents[:,1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# principalDf = StandardScaler().fit_transform(principalDf[:])\n",
    "\n",
    "# x = principalDf.values\n",
    "\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessing import remove_outliers, handle_nans\n",
    "\n",
    "_, pca_outliers = remove_outliers(principalDf, principalDf.columns)\n",
    "print(pca_outliers, \"\\n\")\n",
    "\n",
    "i = 1\n",
    "\n",
    "while pca_outliers.any() == True: # checking non-zero existence\n",
    "    print(f\"Iteration #{i}...\")\n",
    "    principalDf, pca_outliers = remove_outliers(principalDf, pca_outliers[pca_outliers > 0].index.tolist())\n",
    "    principalDf = handle_nans(principalDf, pca_outliers[pca_outliers > 0].index.tolist())\n",
    "    principalDf[:] = StandardScaler().fit_transform(principalDf[:])\n",
    "    i += 1\n",
    "\n",
    "print(\"No outliers after standardization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(principalDf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the PCA algorithm with our Data\n",
    "pca = PCA().fit(principalDf)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "# Plotting the Cumulative Summation of the Explained Variance\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.title('Explained Variance')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "secondComponents = pca.fit_transform(principalDf)\n",
    "\n",
    "secondDf = pd.DataFrame(data = secondComponents, columns = ['pc_1', 'pc_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = secondComponents\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    kmeans.fit(x)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_number_of_clusters = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=best_number_of_clusters, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "pred_y = kmeans.fit_predict(x)\n",
    "plt.scatter(x[:,0], x[:,1])\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Awful results. However, agglomerative clustering seems to be better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as shc\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms\")\n",
    "dend = shc.dendrogram(shc.linkage(x, method='ward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "n_clusters = 4\n",
    "\n",
    "cluster = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')\n",
    "cluster.fit_predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(x[:,0], x[:,1], c=cluster.labels_, cmap='rainbow')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
